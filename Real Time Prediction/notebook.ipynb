{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/regenerated_landslide_risk_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Precipitation (mm)</th>\n",
       "      <th>Soil Moisture (%)</th>\n",
       "      <th>Elevation (m)</th>\n",
       "      <th>Landslide Risk Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>68</td>\n",
       "      <td>176</td>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "      <td>672</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>81</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>36</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>53</td>\n",
       "      <td>136</td>\n",
       "      <td>70</td>\n",
       "      <td>583</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature (°C)  Humidity (%)  Precipitation (mm)  Soil Moisture (%)  \\\n",
       "0                17            68                 176                 64   \n",
       "1                26            33                  65                 24   \n",
       "2                16            81                  56                 52   \n",
       "3                25            53                 136                 70   \n",
       "4                34            77                  23                 37   \n",
       "\n",
       "   Elevation (m) Landslide Risk Prediction  \n",
       "0            120                       Low  \n",
       "1            672                       Low  \n",
       "2             36                       Low  \n",
       "3            583                       Low  \n",
       "4            130                       Low  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Temperature (°C)', 'Humidity (%)', 'Precipitation (mm)',\n",
       "       'Soil Moisture (%)', 'Elevation (m)', 'Landslide Risk Prediction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Landslide Risk Prediction\n",
       "Low          4591\n",
       "Moderate      334\n",
       "High           63\n",
       "Very High      12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Landslide Risk Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Landslide Risk Prediction'] = df['Landslide Risk Prediction'].apply(lambda x: 0 if x == 'Low' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Landslide Risk Prediction\n",
       "0    4591\n",
       "1     409\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Landslide Risk Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is loaded from previous script\n",
    "# Replace with your data loading if running separately\n",
    "\n",
    "# Set up plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# Class distribution visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Landslide Risk Prediction', data=df)\n",
    "plt.title('Class Distribution (Imbalance Visualization)')\n",
    "plt.savefig('./images/class_imbalance.png')\n",
    "plt.close()\n",
    "\n",
    "# Distribution of features by class\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(df.columns[:-1]):\n",
    "    sns.boxplot(x='Landslide Risk Prediction', y=feature, data=df, ax=axes[i])\n",
    "    axes[i].set_title(f'{feature} by Landslide Risk')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/feature_distribution_by_class.png')\n",
    "plt.close()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation = df.corr()\n",
    "mask = np.triu(correlation)\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', mask=mask, vmin=-1, vmax=1)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/correlation_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# Feature distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(df.columns[:-1]):\n",
    "    sns.histplot(df[feature], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/feature_distributions.png')\n",
    "plt.close()\n",
    "\n",
    "# Pairplot for feature relationships\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.pairplot(df, hue='Landslide Risk Prediction', corner=True)\n",
    "plt.savefig('./images/pairplot.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature differences between classes:\n",
      "Temperature (°C): p-value = 0.7000 \n",
      "Humidity (%): p-value = 0.0000 (significant)\n",
      "Precipitation (mm): p-value = 0.0000 (significant)\n",
      "Soil Moisture (%): p-value = 0.0000 (significant)\n",
      "Elevation (m): p-value = 0.0000 (significant)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming df is loaded from previous scripts\n",
    "# Replace with your data loading if running separately\n",
    "\n",
    "# Feature scaling for PCA\n",
    "X = df.drop('Landslide Risk Prediction', axis=1)\n",
    "y = df['Landslide Risk Prediction']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA for dimensionality reduction visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "pca_df = pd.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'Landslide Risk': y\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Landslide Risk', \n",
    "                data=pca_df, palette=['skyblue', 'salmon'], s=100)\n",
    "plt.title('PCA: First Two Principal Components')\n",
    "plt.savefig('pca_visualization.png')\n",
    "plt.close()\n",
    "\n",
    "# Statistical tests to compare features between classes\n",
    "print(\"Feature differences between classes:\")\n",
    "for feature in X.columns:\n",
    "    class0 = df[df['Landslide Risk Prediction'] == 0][feature]\n",
    "    class1 = df[df['Landslide Risk Prediction'] == 1][feature]\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(class0, class1, equal_var=False)\n",
    "    \n",
    "    print(f\"{feature}: p-value = {p_val:.4f} {'(significant)' if p_val < 0.05 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create preprocessing pipeline\n",
    "def create_preprocessing_pipeline(numeric_features, categorical_features=None):\n",
    "    \"\"\"\n",
    "    Create a scikit-learn preprocessing pipeline for numeric and categorical features\n",
    "    \"\"\"\n",
    "    transformers = []\n",
    "    \n",
    "    # Numeric features pipeline\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    transformers.append(('num', numeric_transformer, numeric_features))\n",
    "    \n",
    "    # Categorical features pipeline (if any)\n",
    "    if categorical_features:\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "        transformers.append(('cat', categorical_transformer, categorical_features))\n",
    "    \n",
    "    # Create the preprocessor\n",
    "    preprocessor = ColumnTransformer(transformers=transformers)\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate models with different resampling techniques\n",
    "def train_evaluate_models(X, y, preprocessor, models_dict, cv=5):\n",
    "    \"\"\"\n",
    "    Train and evaluate different models with different resampling strategies\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Resampling strategies\n",
    "    resampling_strategies = {\n",
    "        'No Resampling': None,\n",
    "        'SMOTE': SMOTE(random_state=42),\n",
    "        'ADASYN': ADASYN(random_state=42),\n",
    "        'Undersampling': RandomUnderSampler(random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    models = {}\n",
    "    \n",
    "    # For visualization\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    for strategy_name, resampler in resampling_strategies.items():\n",
    "        print(f\"\\n{'-'*50}\\nTraining models with {strategy_name}\\n{'-'*50}\")\n",
    "        \n",
    "        strategy_results = {}\n",
    "        \n",
    "        for model_name, model in models_dict.items():\n",
    "            print(f\"\\nTraining {model_name}...\")\n",
    "            \n",
    "            # Create pipeline with or without resampling\n",
    "            if resampler:\n",
    "                pipeline = ImbPipeline([\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('resampler', resampler),\n",
    "                    ('classifier', model)\n",
    "                ])\n",
    "            else:\n",
    "                pipeline = Pipeline([\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('classifier', model)\n",
    "                ])\n",
    "            \n",
    "            # Train and evaluate the model\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            \n",
    "            # Calculate ROC curve and AUC\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            # Calculate Precision-Recall curve and AUC\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "            pr_auc = average_precision_score(y_test, y_pred_proba)\n",
    "            \n",
    "            # Store results\n",
    "            strategy_results[model_name] = {\n",
    "                'pipeline': pipeline,\n",
    "                'f1_score': f1,\n",
    "                'roc_auc': roc_auc,\n",
    "                'pr_auc': pr_auc,\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba\n",
    "            }\n",
    "            \n",
    "            print(f\"F1 Score: {f1:.4f}\")\n",
    "            print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "            print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # Plot confusion matrix\n",
    "            plt.subplot(4, len(models_dict), len(models_dict) * list(resampling_strategies.keys()).index(strategy_name) + list(models_dict.keys()).index(model_name) + 1)\n",
    "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "            sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "            plt.title(f\"{strategy_name} - {model_name}\\nConfusion Matrix\")\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            \n",
    "            # Save the model\n",
    "            models[f\"{strategy_name}_{model_name}\"] = pipeline\n",
    "        \n",
    "        results[strategy_name] = strategy_results\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrices.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (strategy_name, strategy_results) in enumerate(results.items()):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        for model_name, metrics in strategy_results.items():\n",
    "            plt.plot(metrics['fpr'], metrics['tpr'], label=f\"{model_name} (AUC = {metrics['roc_auc']:.2f})\")\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve - {strategy_name}')\n",
    "        plt.legend(loc='lower right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('roc_curves.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot Precision-Recall curves\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (strategy_name, strategy_results) in enumerate(results.items()):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        for model_name, metrics in strategy_results.items():\n",
    "            plt.plot(metrics['recall'], metrics['precision'], label=f\"{model_name} (AUC = {metrics['pr_auc']:.2f})\")\n",
    "        \n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title(f'Precision-Recall Curve - {strategy_name}')\n",
    "        plt.legend(loc='lower left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pr_curves.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot feature importance for tree-based models\n",
    "    for strategy_name, strategy_results in results.items():\n",
    "        for model_name, metrics in strategy_results.items():\n",
    "            if model_name in ['Random Forest', 'Gradient Boosting', 'XGBoost']:\n",
    "                pipeline = metrics['pipeline']\n",
    "                \n",
    "                # Get feature names after preprocessing\n",
    "                if hasattr(pipeline['preprocessor'], 'get_feature_names_out'):\n",
    "                    feature_names = pipeline['preprocessor'].get_feature_names_out()\n",
    "                else:\n",
    "                    feature_names = [f'feature_{i}' for i in range(pipeline['classifier'].feature_importances_.shape[0])]\n",
    "                \n",
    "                # Get feature importances\n",
    "                if model_name == 'XGBoost':\n",
    "                    importances = pipeline['classifier'].feature_importances_\n",
    "                else:\n",
    "                    importances = pipeline['classifier'].feature_importances_\n",
    "                \n",
    "                # Plot\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                indices = np.argsort(importances)[::-1]\n",
    "                plt.title(f'Feature Importances - {strategy_name} - {model_name}')\n",
    "                plt.barh(range(min(10, len(indices))), importances[indices][:10], align='center')\n",
    "                plt.yticks(range(min(10, len(indices))), [feature_names[i] for i in indices][:10])\n",
    "                plt.xlabel('Relative Importance')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'feature_importance_{strategy_name}_{model_name}.png')\n",
    "                plt.close()\n",
    "    \n",
    "    return results, models, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                     Non-Null Count  Dtype\n",
      "---  ------                     --------------  -----\n",
      " 0   Temperature (°C)           5000 non-null   int64\n",
      " 1   Humidity (%)               5000 non-null   int64\n",
      " 2   Precipitation (mm)         5000 non-null   int64\n",
      " 3   Soil Moisture (%)          5000 non-null   int64\n",
      " 4   Elevation (m)              5000 non-null   int64\n",
      " 5   Landslide Risk Prediction  5000 non-null   int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 234.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n",
      "Landslide Risk Prediction\n",
      "0    4591\n",
      "1     409\n",
      "Name: count, dtype: int64\n",
      "Class imbalance ratio: 1:11.22\n",
      "\n",
      "--------------------------------------------------\n",
      "Training models with No Resampling\n",
      "--------------------------------------------------\n",
      "\n",
      "Training Logistic Regression...\n",
      "F1 Score: 0.5776\n",
      "ROC AUC: 0.9713\n",
      "PR AUC: 0.7446\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93       918\n",
      "           1       0.41      0.98      0.58        82\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.70      0.93      0.75      1000\n",
      "weighted avg       0.95      0.88      0.90      1000\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "F1 Score: 0.9939\n",
      "ROC AUC: 0.9999\n",
      "PR AUC: 0.9984\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       918\n",
      "           1       1.00      0.99      0.99        82\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "F1 Score: 0.9939\n",
      "ROC AUC: 1.0000\n",
      "PR AUC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       918\n",
      "           1       1.00      0.99      0.99        82\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "F1 Score: 0.7847\n",
      "ROC AUC: 0.9965\n",
      "PR AUC: 0.9629\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       918\n",
      "           1       0.65      1.00      0.78        82\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.82      0.98      0.88      1000\n",
      "weighted avg       0.97      0.95      0.96      1000\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "F1 Score: 0.9939\n",
      "ROC AUC: 0.9996\n",
      "PR AUC: 0.9969\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       918\n",
      "           1       1.00      0.99      0.99        82\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training models with SMOTE\n",
      "--------------------------------------------------\n",
      "\n",
      "Training Logistic Regression...\n",
      "F1 Score: 0.5839\n",
      "ROC AUC: 0.9710\n",
      "PR AUC: 0.7425\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93       918\n",
      "           1       0.42      0.98      0.58        82\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.71      0.93      0.76      1000\n",
      "weighted avg       0.95      0.89      0.91      1000\n",
      "\n",
      "\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [21:43:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9939\n",
      "ROC AUC: 1.0000\n",
      "PR AUC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       918\n",
      "           1       1.00      0.99      0.99        82\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "PR AUC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       918\n",
      "           1       1.00      1.00      1.00        82\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "F1 Score: 0.8482\n",
      "ROC AUC: 0.9963\n",
      "PR AUC: 0.9606\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       918\n",
      "           1       0.74      0.99      0.85        82\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.87      0.98      0.92      1000\n",
      "weighted avg       0.98      0.97      0.97      1000\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "PR AUC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       918\n",
      "           1       1.00      1.00      1.00        82\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training models with ADASYN\n",
      "--------------------------------------------------\n",
      "\n",
      "Training Logistic Regression...\n",
      "F1 Score: 0.5351\n",
      "ROC AUC: 0.9704\n",
      "PR AUC: 0.7360\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92       918\n",
      "           1       0.37      0.98      0.54        82\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.68      0.91      0.73      1000\n",
      "weighted avg       0.95      0.86      0.89      1000\n",
      "\n",
      "\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [21:43:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9939\n",
      "ROC AUC: 1.0000\n",
      "PR AUC: 0.9999\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       918\n",
      "           1       1.00      0.99      0.99        82\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "PR AUC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       918\n",
      "           1       1.00      1.00      1.00        82\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "F1 Score: 0.8283\n",
      "ROC AUC: 0.9959\n",
      "PR AUC: 0.9573\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       918\n",
      "           1       0.71      1.00      0.83        82\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.85      0.98      0.90      1000\n",
      "weighted avg       0.98      0.97      0.97      1000\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "PR AUC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       918\n",
      "           1       1.00      1.00      1.00        82\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training models with Undersampling\n",
      "--------------------------------------------------\n",
      "\n",
      "Training Logistic Regression...\n",
      "F1 Score: 0.5654\n",
      "ROC AUC: 0.9720\n",
      "PR AUC: 0.7569\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93       918\n",
      "           1       0.40      0.98      0.57        82\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.70      0.92      0.75      1000\n",
      "weighted avg       0.95      0.88      0.90      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [21:43:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest...\n",
      "F1 Score: 0.9820\n",
      "ROC AUC: 1.0000\n",
      "PR AUC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       918\n",
      "           1       0.96      1.00      0.98        82\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       0.98      1.00      0.99      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "F1 Score: 0.9704\n",
      "ROC AUC: 1.0000\n",
      "PR AUC: 0.9996\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       918\n",
      "           1       0.94      1.00      0.97        82\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.97      1.00      0.98      1000\n",
      "weighted avg       1.00      0.99      1.00      1000\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "F1 Score: 0.6949\n",
      "ROC AUC: 0.9937\n",
      "PR AUC: 0.9352\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       918\n",
      "           1       0.53      1.00      0.69        82\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.77      0.96      0.83      1000\n",
      "weighted avg       0.96      0.93      0.94      1000\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "F1 Score: 0.9591\n",
      "ROC AUC: 1.0000\n",
      "PR AUC: 0.9999\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       918\n",
      "           1       0.92      1.00      0.96        82\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.96      1.00      0.98      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [21:43:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: Gradient Boosting with SMOTE, F1 Score: 1.0000\n",
      "Best model saved as 'best_landslide_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the data (replace with your file path)\n",
    "    \n",
    "    # Define features and target\n",
    "    X = df.drop('Landslide Risk Prediction', axis=1)  # Assuming 'Landslide' is the target column\n",
    "    y = df['Landslide Risk Prediction']\n",
    "    \n",
    "    # Check class imbalance\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(y.value_counts())\n",
    "    print(f\"Class imbalance ratio: 1:{y.value_counts()[0]/y.value_counts()[1]:.2f}\")\n",
    "    \n",
    "    # Define feature types\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Create preprocessing pipeline\n",
    "    preprocessor = create_preprocessing_pipeline(numeric_features, categorical_features)\n",
    "    \n",
    "    # Define models to try\n",
    "    models_dict = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        'SVM': SVC(probability=True, class_weight='balanced', random_state=42),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    results, models, X_test, y_test = train_evaluate_models(X, y, preprocessor, models_dict)\n",
    "    \n",
    "    # Find best model based on F1 score\n",
    "    best_f1 = 0\n",
    "    best_model_name = \"\"\n",
    "    best_strategy = \"\"\n",
    "    \n",
    "    for strategy_name, strategy_results in results.items():\n",
    "        for model_name, metrics in strategy_results.items():\n",
    "            if metrics['f1_score'] > best_f1:\n",
    "                best_f1 = metrics['f1_score']\n",
    "                best_model_name = model_name\n",
    "                best_strategy = strategy_name\n",
    "    \n",
    "    print(f\"\\nBest model: {best_model_name} with {best_strategy}, F1 Score: {best_f1:.4f}\")\n",
    "      # Save the best model\n",
    "    import joblib\n",
    "    best_model = models[f\"{best_strategy}_{best_model_name}\"]\n",
    "    joblib.dump(best_model, 'best_landslide_model.pkl')\n",
    "    print(\"Best model saved as 'best_landslide_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
